{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502f1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87aa075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "url = 'https://www.daraz.pk/'\n",
    "driver.get(url)\n",
    "search_bar = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div/div[2]/div/div[2]/form/div/div[1]/input[1]')\n",
    "search_bar.send_keys('Mobile Phones' + Keys.RETURN)\n",
    "next_button = driver.find_element(By.XPATH, '/html/body/div[3]/div/div[3]/div/div/div[1]/div[3]/div/div/ul/li[9]/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4471ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"window.scrollTo(0,500);\")\n",
    "time.sleep(2)\n",
    "side_grid = driver.find_element(By.XPATH, '/html/body/div[3]/div/div[3]/div/div/div[2]/div/div[3]/div[2]/div/div[1]')\n",
    "lines= side_grid.find_elements(By.CLASS_NAME, 'category-list__item--RCyN7')\n",
    "for i in lines:\n",
    "    if i.text == 'Mobiles':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b429de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "73a0a52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No Reviews\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No Reviews\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No Reviews\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No Reviews\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No Reviews\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No Reviews\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No Reviews\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n",
      "No Reviews\n",
      "No Reviews\n",
      "No More Pages\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=119.0.6045.200)\nStacktrace:\n\tGetHandleVerifier [0x00AF72A3+45731]\n\t(No symbol) [0x00A82D51]\n\t(No symbol) [0x0097880D]\n\t(No symbol) [0x0096A644]\n\t(No symbol) [0x0096A339]\n\t(No symbol) [0x0097A270]\n\t(No symbol) [0x009DB2F3]\n\t(No symbol) [0x009C7DD6]\n\t(No symbol) [0x009A31F6]\n\t(No symbol) [0x009A439D]\n\tGetHandleVerifier [0x00E00716+3229462]\n\tGetHandleVerifier [0x00E484C8+3523784]\n\tGetHandleVerifier [0x00E4214C+3498316]\n\tGetHandleVerifier [0x00B81680+611968]\n\t(No symbol) [0x00A8CCCC]\n\t(No symbol) [0x00A88DF8]\n\t(No symbol) [0x00A88F1D]\n\t(No symbol) [0x00A7B2C7]\n\tBaseThreadInitThunk [0x774C6839+25]\n\tRtlGetFullPathName_UEx [0x77AF906F+1215]\n\tRtlGetFullPathName_UEx [0x77AF903D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 71\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m#extract overall rating\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     rating_box\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[4]/div/div[9]/div[1]/div[2]/div/div/div/div[1]/div[2]/div/div/div[1]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     72\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(rating_box\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore-average\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (NoSuchElementException,StaleElementReferenceException) \u001b[38;5;28;01mas\u001b[39;00m e :\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    738\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    739\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=119.0.6045.200)\nStacktrace:\n\tGetHandleVerifier [0x00AF72A3+45731]\n\t(No symbol) [0x00A82D51]\n\t(No symbol) [0x0097880D]\n\t(No symbol) [0x0096A644]\n\t(No symbol) [0x0096A339]\n\t(No symbol) [0x0097A270]\n\t(No symbol) [0x009DB2F3]\n\t(No symbol) [0x009C7DD6]\n\t(No symbol) [0x009A31F6]\n\t(No symbol) [0x009A439D]\n\tGetHandleVerifier [0x00E00716+3229462]\n\tGetHandleVerifier [0x00E484C8+3523784]\n\tGetHandleVerifier [0x00E4214C+3498316]\n\tGetHandleVerifier [0x00B81680+611968]\n\t(No symbol) [0x00A8CCCC]\n\t(No symbol) [0x00A88DF8]\n\t(No symbol) [0x00A88F1D]\n\t(No symbol) [0x00A7B2C7]\n\tBaseThreadInitThunk [0x774C6839+25]\n\tRtlGetFullPathName_UEx [0x77AF906F+1215]\n\tRtlGetFullPathName_UEx [0x77AF903D+1165]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=dict()\n",
    "data[\"ID\"]=[]\n",
    "data[\"descriptions\"] = []\n",
    "data[\"prices\"]= []\n",
    "data[\"Brand\"]=[]\n",
    "data[\"rating\"]=[]\n",
    "data[\"free_shipping\"]=[]\n",
    "data[\"daraz_mall\"]=[]\n",
    "data[\"seller_rating\"]=[]\n",
    "data[\"ontime_rating\"]=[]\n",
    "count=1\n",
    "\n",
    "temp = dict()\n",
    "temp['ID']=[]\n",
    "temp['Name'] = []\n",
    "temp['Review text'] = []\n",
    "#loop through pages \n",
    "for page in range(0,5):\n",
    "    #find the ad grid and ad cards on the page\n",
    "    ad_grid = driver.find_element(By.XPATH, '/html/body/div[3]/div/div[3]/div/div/div[1]/div[2]')\n",
    "    ad_cards = ad_grid.find_elements(By.CLASS_NAME, 'gridItem--Yd0sa')\n",
    "\n",
    "#loop through each ad card\n",
    "    for i in ad_cards:\n",
    "        try:\n",
    "            #extract information from the ad card\n",
    "            data[\"descriptions\"].append(i.find_element(By.CLASS_NAME, 'title--wFj93').text)\n",
    "            data[\"prices\"].append(i.find_element(By.CLASS_NAME, 'price--NVB62').text)\n",
    "            data[\"free_shipping\"].append(i.find_element(By.CLASS_NAME, 'location--eh0Ro').text)\n",
    "            data['ID'].append(count)\n",
    "            #check for Daraz Mall badge\n",
    "            try:\n",
    "                element = i.find_element(By.XPATH, '/html/body/div[3]/div/div[3]/div/div/div[1]/div[2]/div[39]/div/div/div[2]/div[1]/i')\n",
    "                data[\"daraz_mall\"].append(1)\n",
    "            except NoSuchElementException:\n",
    "                data[\"daraz_mall\"].append(0)\n",
    "\n",
    "            #click on the product link and switch to the new tab\n",
    "            product_link_element = i.find_element(By.ID, 'id-a-link')\n",
    "            product_link_element.send_keys(Keys.CONTROL + Keys.RETURN)\n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "            #in present tab\n",
    "            time.sleep(2)\n",
    "            try:\n",
    "                data[\"Brand\"].append(driver.find_element(By.XPATH, '/html/body/div[4]/div/div[3]/div[2]/div/div[1]/div[5]/div/a[1]').text)\n",
    "            except (NoSuchElementException,StaleElementReferenceException) as e :\n",
    "                data[\"Brand\"].append(\"not found\")\n",
    "            #extract information from the new tab\n",
    "            percentage_grid = driver.find_element(By.XPATH, '/html/body/div[4]/div/div[3]/div[2]/div/div[2]/div[5]/div/div[2]')\n",
    "            boxes=percentage_grid.find_elements(By.CLASS_NAME, 'info-content')\n",
    "            #extract seller rating and on-time rating\n",
    "            try:\n",
    "                data[\"seller_rating\"].append(boxes[0].find_element(By.CLASS_NAME, 'rating-positive').text)\n",
    "            except (NoSuchElementException,StaleElementReferenceException) as e :\n",
    "                data[\"seller_rating\"].append('0%')\n",
    "\n",
    "            try:\n",
    "                data[\"ontime_rating\"].append(boxes[1].find_element(By.CLASS_NAME, 'seller-info-value').text)\n",
    "            except (NoSuchElementException,StaleElementReferenceException) as e :\n",
    "                data[\"ontime_rating\"].append('0%')\n",
    "            \n",
    "            #scroll down to load more content\n",
    "            driver.execute_script(\"window.scrollTo(0,1800);\")\n",
    "            \n",
    "            time.sleep(5)\n",
    "            #extract overall rating\n",
    "            try:\n",
    "                rating_box=driver.find_element(By.XPATH,'/html/body/div[4]/div/div[9]/div[1]/div[2]/div/div/div/div[1]/div[2]/div/div/div[1]')\n",
    "                data[\"rating\"].append(rating_box.find_element(By.CLASS_NAME, 'score-average').text)\n",
    "            except (NoSuchElementException,StaleElementReferenceException) as e :\n",
    "                data[\"rating\"].append(\"not found\")\n",
    "\n",
    "            time.sleep(2)\n",
    "            \n",
    "            \n",
    "            ####################reviews\n",
    "            driver.execute_script(\"window.scrollTo(0, 500);\")\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\"window.scrollTo(500, 800);\")\n",
    "\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\"window.scrollTo(800, 1000);\")\n",
    "            time.sleep(2)\n",
    "\n",
    "            #looping through review pages\n",
    "            for page in range(0,3):\n",
    "                try:\n",
    "                    # Finding the container for reviews\n",
    "                    reviews_container = driver.find_element(By.CLASS_NAME, 'review-content')\n",
    "                except NoSuchElementException:\n",
    "                    print('No Reviews')\n",
    "                    break\n",
    "                    #finding all individual reviews on the current page\n",
    "                reviews = reviews_container.find_elements(By.CLASS_NAME,'review-item')\n",
    "\n",
    "                #looping through each review on the current page\n",
    "                for i in range(len(reviews)):\n",
    "                    temp['ID'].append(count)\n",
    "                    temp['Name'].append(reviews[i].find_element(By.CLASS_NAME,'user').text)\n",
    "                    temp['Review text'].append(reviews[i].find_element(By.CLASS_NAME,'review-content-sl').text)\n",
    "\n",
    "                try:\n",
    "                    nxt_button = driver.find_element(By.XPATH, '/html/body/div[4]/div/div[9]/div[1]/div[1]/div/div/div/div[3]/div[4]/ul/li[9]/button')\n",
    "                    driver.execute_script(\"arguments[0].click();\", nxt_button)\n",
    "                    time.sleep(5)\n",
    "                except NoSuchElementException:\n",
    "                    print('No More Pages')\n",
    "                    break\n",
    "            #converting to dataframe\n",
    "            reviews = pd.DataFrame(temp)\n",
    "            reviews.to_csv('Reviews.csv')\n",
    "            \n",
    "            \n",
    "            #close the new tab and switch back to the original tab\n",
    "            driver.close()\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "        except(NoSuchElementException,StaleElementReferenceException) as e :\n",
    "            print(e)\n",
    "            #convert to dataframe and save to csv after every page\n",
    "        count+=1\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv('Products.csv')\n",
    "        #click on next button to load page\n",
    "    next_button.click()\n",
    "    #add a delay to allow the new page to load\n",
    "    time.sleep(5)\n",
    "#     print(i)\n",
    "#     print(page)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "797a74d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter mobile that u want: Samsung phone\n",
      "Rs. 34,999\n",
      "Rs. 54,999\n",
      "Rs. 72,999\n",
      "Rs. 42,999\n",
      "Rs. 51,999\n",
      "Rs. 29,999\n",
      "Rs. 128,999\n",
      "Rs. 39,999\n",
      "Rs. 34,999\n",
      "Rs. 54,999\n",
      "Rs. 72,999\n",
      "Rs. 42,999\n",
      "Rs. 51,999\n",
      "Rs. 29,999\n",
      "Rs. 128,999\n",
      "Rs. 39,999\n",
      "Rs. 29,999\n",
      "Rs. 134,999\n",
      "Rs. 28,699\n",
      "Rs. 139,999\n",
      "Rs. 23,499\n",
      "Rs. 53,999\n",
      "Rs. 38,999\n",
      "Rs. 43,499\n",
      "Rs. 135,999\n",
      "Rs. 134,999\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def tokenize_input(user_input):\n",
    "    tokens = word_tokenize(user_input)#.lower())\n",
    "    return [word for word in tokens]\n",
    "\n",
    "query=input(\"Enter mobile that u want: \")\n",
    "tokenized_query=tokenize_input(query)\n",
    "\n",
    "data = pd.read_csv('Products.csv')\n",
    "df = pd.DataFrame(data)\n",
    "matching_indexes=[]\n",
    "for word in tokenized_query:\n",
    "    #for Brand\n",
    "    for index, brand in enumerate(df['Brand']):\n",
    "        if word in brand:\n",
    "            matching_indexes.append(index)\n",
    "    \n",
    "for i in matching_indexes:\n",
    "    print(df['prices'][i])\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad658f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cf85e2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Products.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 34\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03mdownload punkt module from nltk, The punkt module is responsible for tokenization\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     32\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProducts.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03mnow we will tokenize all words of column name of dataframe containing all extracted information from scraping from daraz\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#tokenize all words in the 'name' column and create a set of unique tokens\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Products.csv'"
     ]
    }
   ],
   "source": [
    "#programming the chatbot\n",
    "\n",
    "#tokenizing names and then matching from tokens of user's input sentence\n",
    "\n",
    "'''\n",
    "\n",
    "import necessary libraries\n",
    "\n",
    "'''\n",
    "# import pandas library which is required for functionalities with your dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "import nltk library (Natural Language Toolkit)\n",
    "\n",
    "'''\n",
    "import nltk\n",
    "\n",
    "'''\n",
    "\n",
    "from nltk library import word tokenize and sentence tokenizing features\n",
    "\n",
    "'''\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "'''\n",
    "\n",
    "download punkt module from nltk, The punkt module is responsible for tokenization\n",
    "\n",
    "'''\n",
    "nltk.download('punkt')\n",
    "\n",
    "df=pd.read_csv('Products.csv')\n",
    "'''\n",
    "\n",
    "now we will tokenize all words of column name of dataframe containing all extracted information from scraping from daraz\n",
    "\n",
    "'''\n",
    "#tokenize all words in the 'name' column and create a set of unique tokens\n",
    "\n",
    "'''\n",
    "\n",
    "Tokenize all words in the 'name' column, convert to lowercase, and create a set of unique tokens\n",
    "'''\n",
    "name_tokens = set(word_tokenize(' '.join(df['name']).lower()))\n",
    "\n",
    "'''\n",
    "\n",
    "function to tokenize input sentence entered by user\n",
    "\n",
    "'''\n",
    "def tokens(user_sentence):\n",
    "    \n",
    "    #tokenize user's sentence by .lower() function and then yield it\n",
    "    return word_tokenize(user_sentence.lower())\n",
    "\n",
    "'''\n",
    "\n",
    "not extract mobile information based on words that match in name column and user's input sentence\n",
    "\n",
    "'''\n",
    "\n",
    "#function to retrieve mobile information based on user input\n",
    "\n",
    "#this function takes 3 parameters user_ sentence to convert it to tokens and match it to tokens of column name tokenized above and dataframe df\n",
    "\n",
    "def mobile_info(user_sentence, name_tokens, df):\n",
    "    \n",
    "    #word tokenize user input\n",
    "    words = tokens(user_sentence)\n",
    "    '''\n",
    "    \n",
    "    now find words which are common in tokens of user sentence and tokens of name columns that stores names of mobile\n",
    "    \n",
    "    '''\n",
    "    #find common tokens between user input and mobile names\n",
    "\n",
    "    final = set(words) & name_tokens\n",
    "    \n",
    "    #if words doesnt match then display a message to user that products is not found\n",
    "    \n",
    "    if not final:\n",
    "        \n",
    "        #display message that this product is not found\n",
    "        \n",
    "        return \"Sorry, I couldn't identify any common words with mobile names in your input\"\n",
    "\n",
    "    #filter DataFrame based on common tokens\n",
    "    \n",
    "    matched= df[df['name'].str.lower().apply(lambda x: any(token in x for token in final))]\n",
    "\n",
    "    #if no information is gathered then display the message that no phones found\n",
    "    \n",
    "    if matched .empty:\n",
    "        # display that no mobiles match the words in user's sentence\n",
    "        return \"Sorry, I couldn't find any mobile phones matching the words in your input.\"\n",
    "\n",
    "    #display information about the matching products\n",
    "    result = \"\"\n",
    "    \n",
    "    #iterate through the matched rows in the DataFrame\n",
    "    for index, row in matched.iterrows():\n",
    "        \n",
    "        #concatenate information about the product to the result string\n",
    "        result += \"Product: {}\\nPrice: {}\\nBrand: {}\\nReviews: {}\\n\\n\".format(row['name'], row['price'], row['brand'], row['reviews'])\n",
    "        \n",
    "    #return the final result string\n",
    "    \n",
    "    return result\n",
    "\n",
    "#Prompt user to enter sentence\n",
    "\n",
    "user_sentence = input(\"Enter a sentence about the phones you want: \")\n",
    "#get information based on user input and print the result\n",
    "output = mobile_info(user_sentence, name_tokens, df)\n",
    "\n",
    "#print output based on users' demand\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb7c18d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No More Pages\n",
      "No More Pages\n",
      "No More Pages\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 34\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrand\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[4]/div/div[3]/div[2]/div/div[1]/div[5]/div/a[1]\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (NoSuchElementException,StaleElementReferenceException) \u001b[38;5;28;01mas\u001b[39;00m e :\n\u001b[0;32m     36\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrand\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=dict()\n",
    "data[\"descriptions\"] = []\n",
    "data[\"prices\"]= []\n",
    "# data[\"ID\"]=[]\n",
    "data[\"Brand\"]=[]\n",
    "\n",
    "\n",
    "temp = dict()\n",
    "temp['ID'] = []\n",
    "temp['Review text'] = []\n",
    "temp['score']=[]\n",
    "for page in range(0,5):\n",
    "    #find the ad grid and ad cards on the page\n",
    "    ad_grid = driver.find_element(By.XPATH, '/html/body/div[3]/div/div[3]/div/div/div[1]/div[2]')\n",
    "    ad_cards = ad_grid.find_elements(By.CLASS_NAME, 'gridItem--Yd0sa')\n",
    "\n",
    "#loop through each ad card\n",
    "    for i in ad_cards:\n",
    "        try:\n",
    "            #extract information from the ad card\n",
    "            data[\"descriptions\"].append(i.find_element(By.CLASS_NAME, 'title--wFj93').text)\n",
    "            data[\"prices\"].append(i.find_element(By.CLASS_NAME, 'price--NVB62').text)\n",
    "\n",
    "            product_link_element = i.find_element(By.ID, 'id-a-link')\n",
    "            product_link_element.send_keys(Keys.CONTROL + Keys.RETURN)\n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "            #in present tab\n",
    "            time.sleep(2)\n",
    "           \n",
    "            try:\n",
    "                data[\"Brand\"].append(driver.find_element(By.XPATH, '/html/body/div[4]/div/div[3]/div[2]/div/div[1]/div[5]/div/a[1]').text)\n",
    "            except (NoSuchElementException,StaleElementReferenceException) as e :\n",
    "                data[\"Brand\"].append(\"not found\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            #scrolling down the page to load reviews\n",
    "            driver.execute_script(\"window.scrollTo(0, 500);\")\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\"window.scrollTo(500, 800);\")\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\"window.scrollTo(800, 1000);\")\n",
    "            time.sleep(2)\n",
    "            driver.execute_script(\"window.scrollTo(1000, 1300);\")\n",
    "            time.sleep(2)\n",
    "            driver.execute_script(\"window.scrollTo(1300, 1600);\")\n",
    "            time.sleep(1)\n",
    "\n",
    "            #looping through review pages\n",
    "            for page in range(0,3):\n",
    "                try:\n",
    "                    # Finding the container for reviews\n",
    "                    reviews_container = driver.find_element(By.XPATH, '//*[@id=\"module_product_review\"]/div/div/div[3]/div[1]')\n",
    "                except NoSuchElementException:\n",
    "                    print('No Reviews')\n",
    "                    break\n",
    "                    #finding all individual reviews on the current page\n",
    "                reviews = reviews_container.find_elements(By.CLASS_NAME,'item')\n",
    "\n",
    "                #looping through each review on the current page\n",
    "                for i in range(len(reviews)):\n",
    "                    #checking if the review text is not empty\n",
    "                    if reviews[i].find_element(By.CSS_SELECTOR, f\"#module_product_review > div > div > div:nth-child(3) > div.mod-reviews > div:nth-child({i+1}) > div.item-content > div.content\").text != '':\n",
    "                        #extracting and appending reviewer name and review text\n",
    "                        temp['Name'].append(reviews[i].find_element(By.CLASS_NAME,'middle').find_element(By.TAG_NAME,'span').text[3:])\n",
    "                        temp['Review text'].append(reviews[i].find_element(By.CSS_SELECTOR, f\"#module_product_review > div > div > div:nth-child(3) > div.mod-reviews > div:nth-child({i+1}) > div.item-content > div.content\").text)\n",
    "                        temp['sentiment'].append('x')\n",
    "                try:\n",
    "                    #clicking the next button if it exists and not on the third page\n",
    "                    if(page != 2):\n",
    "                        nxt_button = driver.find_element(By.XPATH, '//*[@id=\"module_product_review\"]/div/div/div[3]/div[2]/div/button[2]')\n",
    "                        driver.execute_script(\"arguments[0].click();\", nxt_button)\n",
    "                        time.sleep(5)\n",
    "                except NoSuchElementException:\n",
    "                    print('No More Pages')\n",
    "                    break\n",
    "            #converting to dataframe\n",
    "            reviews = pd.DataFrame(temp)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            time.sleep(2)\n",
    "            #close the new tab and switch back to the original tab\n",
    "            driver.close()\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "        except(NoSuchElementException,StaleElementReferenceException) as e :\n",
    "            print(e)\n",
    "            #convert to dataframe and save to csv after every page\n",
    "        df = pd.DataFrame(data)\n",
    "#         df.to_csv('Q3_data.csv')\n",
    "        #click on next button to load page\n",
    "    next_button.click()\n",
    "    #add a delay to allow the new page to load\n",
    "    time.sleep(5)\n",
    "#     print(i)\n",
    "#     print(page)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be87e474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.8.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f7577f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Review text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, Review text, score]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce27096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "url='https://www.daraz.pk/products/12-8gb-128gb-5000mah-33-i421379488-s1989920618.html?spm=a2a0e.searchlist.sku.1.29313de2gohjjQ&search=1'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f30e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "temp = dict()\n",
    "temp['Name'] = []\n",
    "temp['Review text'] = []\n",
    "temp['sentiment']=[]\n",
    "#scrolling down the page to load reviews\n",
    "driver.execute_script(\"window.scrollTo(0, 500);\")\n",
    "time.sleep(1)\n",
    "driver.execute_script(\"window.scrollTo(500, 800);\")\n",
    "\n",
    "time.sleep(1)\n",
    "driver.execute_script(\"window.scrollTo(800, 1000);\")\n",
    "time.sleep(2)\n",
    "\n",
    "#looping through review pages\n",
    "for page in range(0,3):\n",
    "    try:\n",
    "        # Finding the container for reviews\n",
    "        reviews_container = driver.find_element(By.CLASS_NAME, 'review-content')\n",
    "    except NoSuchElementException:\n",
    "        print('No Reviews')\n",
    "        break\n",
    "        #finding all individual reviews on the current page\n",
    "    reviews = reviews_container.find_elements(By.CLASS_NAME,'review-item')\n",
    "\n",
    "    #looping through each review on the current page\n",
    "    for i in range(len(reviews)):\n",
    "        temp['Name'].append(reviews[i].find_element(By.CLASS_NAME,'user').text)\n",
    "        temp['Review text'].append(reviews[i].find_element(By.CLASS_NAME,'review-content-sl').text)\n",
    "\n",
    "    try:\n",
    "        nxt_button = driver.find_element(By.XPATH, '/html/body/div[4]/div/div[9]/div[1]/div[1]/div/div/div/div[3]/div[4]/ul/li[9]/button')\n",
    "        driver.execute_script(\"arguments[0].click();\", nxt_button)\n",
    "        time.sleep(5)\n",
    "    except NoSuchElementException:\n",
    "        print('No More Pages')\n",
    "        break\n",
    "#converting to dataframe\n",
    "reviews = pd.DataFrame(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69d70a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Review text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdul G.</td>\n",
       "      <td>Assalam u Alaikum Received before due date ori...</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S***n</td>\n",
       "      <td>The seller was very cooperative and delivered ...</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*******686</td>\n",
       "      <td>Same as described.. Amazing Packing and receiv...</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S***n</td>\n",
       "      <td>The seller was very cooperative and delivered ...</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3***9</td>\n",
       "      <td>Masha Allah Jo select kia tha wohi same receiv...</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abeel J.</td>\n",
       "      <td>Received within two days same as shown in adve...</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N***.</td>\n",
       "      <td>Absolutely amazing product and 5 star to all s...</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>*******686</td>\n",
       "      <td>Same as described.. Amazing Packing and receiv...</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sidra 0.</td>\n",
       "      <td>jo mng waya tha wohi hai thnkz daraz</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name                                        Review text sentiment\n",
       "0    Abdul G.  Assalam u Alaikum Received before due date ori...         x\n",
       "1       S***n  The seller was very cooperative and delivered ...         x\n",
       "2  *******686  Same as described.. Amazing Packing and receiv...         x\n",
       "3       S***n  The seller was very cooperative and delivered ...         x\n",
       "4       3***9  Masha Allah Jo select kia tha wohi same receiv...         x\n",
       "5    Abeel J.  Received within two days same as shown in adve...         x\n",
       "6       N***.  Absolutely amazing product and 5 star to all s...         x\n",
       "7  *******686  Same as described.. Amazing Packing and receiv...         x\n",
       "8    sidra 0.               jo mng waya tha wohi hai thnkz daraz         x"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
